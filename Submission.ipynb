{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183aaee1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:21.209035Z",
     "iopub.status.busy": "2023-07-30T16:43:21.208552Z",
     "iopub.status.idle": "2023-07-30T16:43:21.653241Z",
     "shell.execute_reply": "2023-07-30T16:43:21.652262Z"
    },
    "papermill": {
     "duration": 0.456397,
     "end_time": "2023-07-30T16:43:21.656063",
     "exception": false,
     "start_time": "2023-07-30T16:43:21.199666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import rasterio\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40611fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:21.670920Z",
     "iopub.status.busy": "2023-07-30T16:43:21.670612Z",
     "iopub.status.idle": "2023-07-30T16:43:24.374338Z",
     "shell.execute_reply": "2023-07-30T16:43:24.373155Z"
    },
    "papermill": {
     "duration": 2.714032,
     "end_time": "2023-07-30T16:43:24.377158",
     "exception": false,
     "start_time": "2023-07-30T16:43:21.663126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/hubmap-tools/accelerate-0.21.0-py3-none-any.whl\r\n",
      "Installing collected packages: accelerate\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 0.20.3\r\n",
      "    Uninstalling accelerate-0.20.3:\r\n",
      "      Successfully uninstalled accelerate-0.20.3\r\n",
      "Successfully installed accelerate-0.21.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --no-deps /kaggle/input/hubmap-tools/accelerate-0.21.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553e7dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:24.392795Z",
     "iopub.status.busy": "2023-07-30T16:43:24.392434Z",
     "iopub.status.idle": "2023-07-30T16:43:26.429718Z",
     "shell.execute_reply": "2023-07-30T16:43:26.428526Z"
    },
    "papermill": {
     "duration": 2.048106,
     "end_time": "2023-07-30T16:43:26.432443",
     "exception": false,
     "start_time": "2023-07-30T16:43:24.384337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/hubmap-tools/smp_pycocotools/wheels/pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --no-deps /kaggle/input/hubmap-tools/smp_pycocotools/wheels/pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320d439c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:26.448878Z",
     "iopub.status.busy": "2023-07-30T16:43:26.448506Z",
     "iopub.status.idle": "2023-07-30T16:43:38.296638Z",
     "shell.execute_reply": "2023-07-30T16:43:38.295589Z"
    },
    "papermill": {
     "duration": 11.859133,
     "end_time": "2023-07-30T16:43:38.299136",
     "exception": false,
     "start_time": "2023-07-30T16:43:26.440003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Mask2FormerImageProcessor#, Mask2FormerConfig\n",
    "type_dict = {0:'blood_vessel', 1:'glomerulus', 2:'unsure'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7c9389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:38.315599Z",
     "iopub.status.busy": "2023-07-30T16:43:38.315013Z",
     "iopub.status.idle": "2023-07-30T16:43:38.329653Z",
     "shell.execute_reply": "2023-07-30T16:43:38.328589Z"
    },
    "papermill": {
     "duration": 0.025684,
     "end_time": "2023-07-30T16:43:38.332146",
     "exception": false,
     "start_time": "2023-07-30T16:43:38.306462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "class CustomDataset_instances:\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.processor = Mask2FormerImageProcessor.from_pretrained(\"/kaggle/input/mask2former-swin-tiny-cityscapes-semantic\",\n",
    "                                                      reduce_labels=True,\n",
    "                                                      ignore_index=255,\n",
    "                                                      do_resize=False, \n",
    "                                                      do_rescale=False, \n",
    "                                                      do_normalize=False)\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        # Load image\n",
    "        item = self.df.iloc[index]\n",
    "        image = rasterio.open(item.path).read()\n",
    "        type_ = ast.literal_eval(item['structure_types'])\n",
    "        coords = ast.literal_eval(item['coordinates'])\n",
    "#         image = image.astype(float) / 255.0  # Normalize image to [0, 1]\n",
    "        image_shape = image.shape[1:]\n",
    "        mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "        pts_array = []\n",
    "        obj_cnt = 1\n",
    "        type_dict = {'blood_vessel':0, 'glomerulus':1, 'unsure':2}\n",
    "        inst2cls = {0:0}\n",
    "        for typ, coord in zip(type_, coords):\n",
    "            if typ == 'unsure':\n",
    "                continue\n",
    "            else:\n",
    "                pts = np.array(coord).reshape((-1, 1, 2)).astype(np.int32)\n",
    "                cv2.fillPoly(mask, [pts], obj_cnt)\n",
    "                inst2cls[obj_cnt] = type_dict[typ]+1\n",
    "                obj_cnt+=1\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image.transpose(1,2,0), mask=mask)\n",
    "            image, mask = transformed['image'], transformed['mask']\n",
    "            image = image.transpose(2,0,1)\n",
    "        if len(inst2cls.keys())==1:\n",
    "            # Some image does not have annotation (all ignored)\n",
    "            inputs = self.processor([image], return_tensors=\"pt\")\n",
    "            inputs = {k:v.squeeze() for k,v in inputs.items()}\n",
    "            inputs[\"class_labels\"] = torch.tensor([3])\n",
    "            inputs[\"mask_labels\"] = torch.zeros((0, inputs[\"pixel_values\"].shape[-2], inputs[\"pixel_values\"].shape[-1]))\n",
    "            return inputs\n",
    "        inputs = self.processor([image], [mask], instance_id_to_semantic_id=inst2cls, return_tensors=\"pt\", reduce_labels=True)\n",
    "        inputs = {k: v.squeeze() if isinstance(v, torch.Tensor) else v[0] for k,v in inputs.items()}\n",
    "#         print(inputs['class_labels'])\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d31f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:38.347479Z",
     "iopub.status.busy": "2023-07-30T16:43:38.347202Z",
     "iopub.status.idle": "2023-07-30T16:43:40.105266Z",
     "shell.execute_reply": "2023-07-30T16:43:40.104231Z"
    },
    "papermill": {
     "duration": 1.768609,
     "end_time": "2023-07-30T16:43:40.107828",
     "exception": false,
     "start_time": "2023-07-30T16:43:38.339219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "ADE_MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "ADE_STD = np.array([58.395, 57.120, 57.375]) / 255\n",
    "\n",
    "# note that you can include more fancy data augmentation methods here\n",
    "train_transform = A.Compose([\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee6a268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:40.124970Z",
     "iopub.status.busy": "2023-07-30T16:43:40.124134Z",
     "iopub.status.idle": "2023-07-30T16:43:40.130805Z",
     "shell.execute_reply": "2023-07-30T16:43:40.129839Z"
    },
    "papermill": {
     "duration": 0.01724,
     "end_time": "2023-07-30T16:43:40.132902",
     "exception": false,
     "start_time": "2023-07-30T16:43:40.115662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    items = torch.stack([example[\"item_id\"] for example in batch])\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in batch])\n",
    "    pixel_mask = torch.stack([example[\"pixel_mask\"] for example in batch])\n",
    "    class_labels = [example[\"class_labels\"] for example in batch]\n",
    "    mask_labels = [example[\"mask_labels\"] for example in batch]\n",
    "    return {\"pixel_values\": pixel_values, \"pixel_mask\": pixel_mask, \"class_labels\": class_labels, \"mask_labels\": mask_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d30cda6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:40.148262Z",
     "iopub.status.busy": "2023-07-30T16:43:40.147982Z",
     "iopub.status.idle": "2023-07-30T16:43:40.701831Z",
     "shell.execute_reply": "2023-07-30T16:43:40.700715Z"
    },
    "papermill": {
     "duration": 0.564597,
     "end_time": "2023-07-30T16:43:40.704555",
     "exception": false,
     "start_time": "2023-07-30T16:43:40.139958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gr = pd.read_csv(\"/kaggle/input/hubmap-train-test/train_grouped.csv\")\n",
    "val_gr = pd.read_csv(\"/kaggle/input/hubmap-train-test/val_grouped.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c32fce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:40.720978Z",
     "iopub.status.busy": "2023-07-30T16:43:40.720328Z",
     "iopub.status.idle": "2023-07-30T16:43:40.730820Z",
     "shell.execute_reply": "2023-07-30T16:43:40.729901Z"
    },
    "papermill": {
     "duration": 0.020733,
     "end_time": "2023-07-30T16:43:40.732946",
     "exception": false,
     "start_time": "2023-07-30T16:43:40.712213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset_instances(train_gr, train_transform)\n",
    "val_dataset = CustomDataset_instances(val_gr, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c149742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:40.749145Z",
     "iopub.status.busy": "2023-07-30T16:43:40.748863Z",
     "iopub.status.idle": "2023-07-30T16:43:43.042482Z",
     "shell.execute_reply": "2023-07-30T16:43:43.041526Z"
    },
    "papermill": {
     "duration": 2.304558,
     "end_time": "2023-07-30T16:43:43.044996",
     "exception": false,
     "start_time": "2023-07-30T16:43:40.740438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27170922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.061230Z",
     "iopub.status.busy": "2023-07-30T16:43:43.060411Z",
     "iopub.status.idle": "2023-07-30T16:43:43.069664Z",
     "shell.execute_reply": "2023-07-30T16:43:43.068667Z"
    },
    "papermill": {
     "duration": 0.019586,
     "end_time": "2023-07-30T16:43:43.071888",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.052302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray, conf) -> t.Text:\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "            mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "            \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "            mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return f\"0 {conf:.2f} {base64_str.decode('utf-8')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6898e684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.087740Z",
     "iopub.status.busy": "2023-07-30T16:43:43.087462Z",
     "iopub.status.idle": "2023-07-30T16:43:43.102503Z",
     "shell.execute_reply": "2023-07-30T16:43:43.101572Z"
    },
    "papermill": {
     "duration": 0.025462,
     "end_time": "2023-07-30T16:43:43.104573",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.079111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mask2Former_pred(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from transformers import Mask2FormerForUniversalSegmentation\n",
    "        self.type_dict = {0:'blood_vessel', 1:'glomerulus', 2:'unsure'}\n",
    "        self.model = Mask2FormerForUniversalSegmentation.from_pretrained(\"/kaggle/input/mask2former-swin-tiny-cityscapes-semantic\", \n",
    "                                                            id2label=self.type_dict,\n",
    "                                                            ignore_mismatched_sizes=True)\n",
    "        self.processor = Mask2FormerImageProcessor.from_pretrained(\"/kaggle/input/mask2former-swin-tiny-cityscapes-semantic\",\n",
    "                                                      reduce_labels=True,\n",
    "                                                      ignore_index=255,\n",
    "                                                      do_resize=False, \n",
    "                                                      do_rescale=False, \n",
    "                                                      do_normalize=False)\n",
    "        self.learning_rate = 5e-5\n",
    "\n",
    "    def forward(self, pixel_values, mask_labels, class_labels):\n",
    "        return self.model(pixel_values, mask_labels, class_labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            pixel_values=batch[\"pixel_values\"],\n",
    "            mask_labels=[labels for labels in batch[\"mask_labels\"]],\n",
    "            class_labels=[labels for labels in batch[\"class_labels\"]],\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            pixel_values=batch[\"pixel_values\"],\n",
    "            mask_labels=[labels for labels in batch[\"mask_labels\"]],\n",
    "            class_labels=[labels for labels in batch[\"class_labels\"]],\n",
    "        )\n",
    "        val_loss = outputs.loss\n",
    "        self.log('val_loss', val_loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "#         print(batch)\n",
    "        outputs = self.model(\n",
    "            pixel_values=batch[\"pixel_values\"],\n",
    "        )\n",
    "        pred_instance_map = self.processor.post_process_instance_segmentation(\n",
    "                            outputs, target_sizes=[(512,512)], return_binary_maps=True\n",
    "\n",
    "                            )[0]\n",
    "\n",
    "        pred_str = []\n",
    "        for d in pred_instance_map['segments_info']:\n",
    "            if d['label_id']==0:\n",
    "                mask = pred_instance_map['segmentation'][d['id']].detach().cpu().numpy().astype(bool)\n",
    "                pred_enc = encode_binary_mask(mask, d['score'])\n",
    "\n",
    "                pred_str.append(pred_enc)\n",
    "        return batch['item_id'][0], 512, 512, \" \".join(pred_str) \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=0.2)\n",
    "\n",
    "        lr_scheduler_cont = {\n",
    "            'scheduler':  torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                                                                        optimizer,\n",
    "                                                                        mode='min',\n",
    "                                                                        factor=0.8,\n",
    "                                                                        patience=50,\n",
    "                                                                        threshold=1e-2,\n",
    "                                                                        min_lr=1e-8,\n",
    "                                                                        verbose=True\n",
    "                                                                    ),\n",
    "            'name': 'learning_rate',\n",
    "            'monitor' : 'train_loss',\n",
    "            \"interval\" : \"step\" \n",
    "        }\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a81217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.119627Z",
     "iopub.status.busy": "2023-07-30T16:43:43.119360Z",
     "iopub.status.idle": "2023-07-30T16:43:43.128033Z",
     "shell.execute_reply": "2023-07-30T16:43:43.127136Z"
    },
    "papermill": {
     "duration": 0.018598,
     "end_time": "2023-07-30T16:43:43.130112",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.111514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "class CustomDataset_pred:\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.processor = Mask2FormerImageProcessor.from_pretrained(\"/kaggle/input/mask2former-swin-tiny-cityscapes-semantic\",\n",
    "                                                      reduce_labels=True,\n",
    "                                                      ignore_index=255,\n",
    "                                                      do_resize=False, \n",
    "                                                      do_rescale=False, \n",
    "                                                      do_normalize=False)\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        # Load image\n",
    "        item = self.df[index]\n",
    "        image = rasterio.open(item).read()\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image.transpose(1,2,0))\n",
    "            image= transformed['image']\n",
    "            image = image.transpose(2,0,1)\n",
    "            \n",
    "        inputs = self.processor([image], return_tensors=\"pt\",reduce_labels=True)\n",
    "        inputs = {k: v.squeeze() if isinstance(v, torch.Tensor) else v[0] for k,v in inputs.items()}\n",
    "        inputs['item_id'] = item.split(\"/\")[-1].split('.')[0]\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2730a26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.145802Z",
     "iopub.status.busy": "2023-07-30T16:43:43.145023Z",
     "iopub.status.idle": "2023-07-30T16:43:43.149479Z",
     "shell.execute_reply": "2023-07-30T16:43:43.148608Z"
    },
    "papermill": {
     "duration": 0.014376,
     "end_time": "2023-07-30T16:43:43.151477",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.137101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a13135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.167018Z",
     "iopub.status.busy": "2023-07-30T16:43:43.166269Z",
     "iopub.status.idle": "2023-07-30T16:43:43.175307Z",
     "shell.execute_reply": "2023-07-30T16:43:43.174443Z"
    },
    "papermill": {
     "duration": 0.018892,
     "end_time": "2023-07-30T16:43:43.177423",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.158531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glob.glob('/kaggle/input/hubmap-hacking-the-human-vasculature/test/*') val_gr['path'].tolist()\n",
    "pred_dataset = CustomDataset_pred(glob.glob('/kaggle/input/hubmap-hacking-the-human-vasculature/test/*'), train_transform)\n",
    "samp_dataloader = torch.utils.data.DataLoader(pred_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e8c86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:43.193164Z",
     "iopub.status.busy": "2023-07-30T16:43:43.192188Z",
     "iopub.status.idle": "2023-07-30T16:43:51.016662Z",
     "shell.execute_reply": "2023-07-30T16:43:51.015610Z"
    },
    "papermill": {
     "duration": 7.834691,
     "end_time": "2023-07-30T16:43:51.019100",
     "exception": false,
     "start_time": "2023-07-30T16:43:43.184409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/utils.py:51: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.5, which is newer than your current Lightning version: v2.0.4\n",
      "  rank_zero_warn(\n",
      "Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at /kaggle/input/mask2former-swin-tiny-cityscapes-semantic and are newly initialized because the shapes did not match:\n",
      "- class_predictor.weight: found shape torch.Size([20, 256]) in the checkpoint and torch.Size([4, 256]) in the model instantiated\n",
      "- class_predictor.bias: found shape torch.Size([20]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- criterion.empty_weight: found shape torch.Size([20]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_pred = Mask2Former_pred.load_from_checkpoint(\"/kaggle/input/hubmap-model-14epch/epoch14-step2460.ckpt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf12e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:43:51.037072Z",
     "iopub.status.busy": "2023-07-30T16:43:51.035319Z",
     "iopub.status.idle": "2023-07-30T16:44:02.237871Z",
     "shell.execute_reply": "2023-07-30T16:44:02.236727Z"
    },
    "papermill": {
     "duration": 11.213648,
     "end_time": "2023-07-30T16:44:02.240342",
     "exception": false,
     "start_time": "2023-07-30T16:43:51.026694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4978df6825414885a4d7ab2a9ed58c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/tmp/ipykernel_25/2411595467.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if mask.dtype != np.bool:\n"
     ]
    }
   ],
   "source": [
    "trainer_pred = pl.Trainer(devices='auto')  # Set the appropriate number of GPUs\n",
    "\n",
    "res = trainer_pred.predict(model_pred, samp_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45efc053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:44:02.257756Z",
     "iopub.status.busy": "2023-07-30T16:44:02.257437Z",
     "iopub.status.idle": "2023-07-30T16:44:02.263512Z",
     "shell.execute_reply": "2023-07-30T16:44:02.262476Z"
    },
    "papermill": {
     "duration": 0.017366,
     "end_time": "2023-07-30T16:44:02.265664",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.248298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(res, columns =[\"id\",\"height\",\"width\",\"prediction_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ba0a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:44:02.282618Z",
     "iopub.status.busy": "2023-07-30T16:44:02.282325Z",
     "iopub.status.idle": "2023-07-30T16:44:02.290410Z",
     "shell.execute_reply": "2023-07-30T16:44:02.289511Z"
    },
    "papermill": {
     "duration": 0.018987,
     "end_time": "2023-07-30T16:44:02.292621",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.273634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab23e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:44:02.309454Z",
     "iopub.status.busy": "2023-07-30T16:44:02.308642Z",
     "iopub.status.idle": "2023-07-30T16:44:02.313621Z",
     "shell.execute_reply": "2023-07-30T16:44:02.312746Z"
    },
    "papermill": {
     "duration": 0.015427,
     "end_time": "2023-07-30T16:44:02.315637",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.300210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_maps = []\n",
    "# for re in tqdm(res):\n",
    "#     pred_instance_map = processor.post_process_instance_segmentation(\n",
    "#         re, target_sizes=[(512,512)], return_binary_maps=True\n",
    "\n",
    "#     )[0]\n",
    "\n",
    "#     pred_str = []\n",
    "#     for d in pred_instance_map['segments_info']:\n",
    "#         if d['label_id']==0:\n",
    "#             mask = pred_instance_map['segmentation'][d['id']].numpy().astype(bool)\n",
    "#             pred_enc = encode_binary_mask(mask, d['score'])\n",
    "\n",
    "#             pred_str.append(pred_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2a0e295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T16:44:02.332525Z",
     "iopub.status.busy": "2023-07-30T16:44:02.331650Z",
     "iopub.status.idle": "2023-07-30T16:44:02.337189Z",
     "shell.execute_reply": "2023-07-30T16:44:02.336331Z"
    },
    "papermill": {
     "duration": 0.016075,
     "end_time": "2023-07-30T16:44:02.339201",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.323126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img= cv2.cvtColor(cv2.imread('/kaggle/input/hubmap-hacking-the-human-vasculature/test/72e40acccadf.tif'), cv2.COLOR_BGR2RGB) #return np array of pixels \n",
    "# plt.figure()\n",
    "# plt.imshow(img)\n",
    "# plt.title(\"Image\")\n",
    "# plt.show()\n",
    "\n",
    "# predicted_semantic_map = processor.post_process_instance_segmentation(outputs, target_sizes=[(512,512)])[0]\n",
    "# color_segmentation_map = pred_instance_map['segmentation']\n",
    "####\n",
    "# for pred_instance_map in pred_maps:\n",
    "#     overlay = np.zeros([512,512])\n",
    "#     pred_str = []\n",
    "#     for d in pred_instance_map['segments_info']:\n",
    "#         if d['label_id']==0:\n",
    "#             mask = pred_instance_map['segmentation'][d['id']].numpy().astype(bool)\n",
    "#             pred_enc = encode_binary_mask(mask, d['score'])\n",
    "# #             print(pred_enc)\n",
    "#             overlay+=pred_instance_map['segmentation'][d['id']].numpy()\n",
    "\n",
    "#         # plt.imshow(img.reshape(512,512,3))\n",
    "#             plt.imshow(overlay, alpha=0.6)\n",
    "#             pred_str.append(pred_enc)\n",
    "#     break\n",
    "####\n",
    "#     print(\" \".join(pred_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9d979",
   "metadata": {
    "papermill": {
     "duration": 0.007238,
     "end_time": "2023-07-30T16:44:02.353904",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.346666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac11b1",
   "metadata": {
    "papermill": {
     "duration": 0.00719,
     "end_time": "2023-07-30T16:44:02.368510",
     "exception": false,
     "start_time": "2023-07-30T16:44:02.361320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54.737401,
   "end_time": "2023-07-30T16:44:05.990776",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-30T16:43:11.253375",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05fa9297e82e4cef89be2344b7684d12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "09f840bec28d43f59e69d3b9621d1ac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "0eb60b6c507f42fbae38b57f9253703b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19de3646b5e243588ebfb06b12910273": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc679b010cb24e97ab578217324e781f",
       "placeholder": "​",
       "style": "IPY_MODEL_f3a45b9bab3642609f32a7280914832e",
       "value": "Predicting DataLoader 0: 100%"
      }
     },
     "4542715b4356453a9e737ef50d50cc13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a00a9b3946040628131ede59715db6a",
       "placeholder": "​",
       "style": "IPY_MODEL_51d2d0e4977147b694903728c8bb2b36",
       "value": " 1/1 [00:05&lt;00:00,  5.33s/it]"
      }
     },
     "4978df6825414885a4d7ab2a9ed58c5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19de3646b5e243588ebfb06b12910273",
        "IPY_MODEL_7d4476866327442bbea3db451eaad980",
        "IPY_MODEL_4542715b4356453a9e737ef50d50cc13"
       ],
       "layout": "IPY_MODEL_09f840bec28d43f59e69d3b9621d1ac2"
      }
     },
     "51d2d0e4977147b694903728c8bb2b36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a00a9b3946040628131ede59715db6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d4476866327442bbea3db451eaad980": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0eb60b6c507f42fbae38b57f9253703b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_05fa9297e82e4cef89be2344b7684d12",
       "value": 1.0
      }
     },
     "cc679b010cb24e97ab578217324e781f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3a45b9bab3642609f32a7280914832e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
